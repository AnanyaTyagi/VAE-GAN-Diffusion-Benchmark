{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnanyaTyagi/VAE-GAN-Diffusion-Benchmark/blob/main/VAE_Image_Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New setup"
      ],
      "metadata": {
        "id": "1tR5bLhfcnO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ┌─────────────────────────────────────────────────────────────┐\n",
        "# │ EVALUATION APPROACH                                         │\n",
        "# │ Challenge: Generated images won’t match specific data items. │\n",
        "# │ Solution: Use FID & IS → compare DISTRIBUTIONS, not pixels.  │\n",
        "# │ Standard in generative research (DALL·E, SD, StyleGAN).      │\n",
        "# └─────────────────────────────────────────────────────────────┘\n",
        "\n",
        "# --- Colab / Environment ---\n",
        "# --- Check GPU and mount Google Drive ---\n",
        "!nvidia-smi -L || true\n",
        "\n",
        "from google.colab import drive\n",
        "try:\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    OUT_DIR = \"/content/drive/MyDrive/vae_cifar10_runs\"   # change if you prefer\n",
        "    DRIVE_OK = True\n",
        "    print(\"✅ Drive mounted, results will be saved to:\", OUT_DIR)\n",
        "except Exception as e:\n",
        "    print(\"⚠️ Drive mount failed:\", e)\n",
        "    OUT_DIR = \"/content/vae_cifar10_runs\"\n",
        "    DRIVE_OK = False\n",
        "    print(\"Saving locally to:\", OUT_DIR)\n",
        "\n",
        "import os\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "import os, json, csv, time, math, random\n",
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "\n",
        "# --- Reproducibility ---\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed); np.random.seed(seed)\n",
        "    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# --- Helpers ---\n",
        "def denorm(x):  # map [-1,1] -> [0,1]\n",
        "    return (x.clamp(-1,1) + 1) / 2\n",
        "\n",
        "def save_grid_pair(orig, recon, path, nrow=8):\n",
        "    grid_o = vutils.make_grid(denorm(orig), nrow=nrow)\n",
        "    grid_r = vutils.make_grid(denorm(recon), nrow=nrow)\n",
        "    combo  = torch.cat([grid_o, grid_r], dim=1)  # stack vertically\n",
        "    vutils.save_image(combo, path)\n",
        "\n",
        "def beta_schedule(epoch, warmup_epochs=10, beta_start=0.0, beta_end=1.0):\n",
        "    if epoch <= warmup_epochs:\n",
        "        t = epoch / max(1, warmup_epochs)\n",
        "        return beta_start + t * (beta_end - beta_start)\n",
        "    return beta_end\n",
        "\n",
        "# --- Config ---\n",
        "@dataclass\n",
        "class CFG:\n",
        "    data_root: str = \"./data\"\n",
        "    out_dir: str = OUT_DIR\n",
        "    batch_size: int = 256\n",
        "    epochs: int = 100        # bump to 100 for full run\n",
        "    lr: float = 1e-3\n",
        "    z_dim: int = 256\n",
        "    num_workers: int = 2\n",
        "    log_interval: int = 100\n",
        "    beta_warmup_epochs: int = 10\n",
        "    beta_start: float = 0.0\n",
        "    beta_end: float = 1.0\n",
        "    grid_n: int = 64\n",
        "    samples_export_total: int = 10_000\n",
        "    samples_export_bs: int = 100\n",
        "    smoke_subset: int = 0   # set to 1000 for a quick smoke test\n",
        "    use_amp: bool = True\n",
        "\n",
        "cfg = CFG()\n",
        "print(\"Saving outputs to:\", cfg.out_dir)\n",
        "with open(os.path.join(cfg.out_dir, \"config.json\"), \"w\") as f:\n",
        "    json.dump(cfg.__dict__, f, indent=2)\n",
        "\n",
        "print(\"PyTorch:\", torch.__version__, \"| CUDA:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zTITGNlc0ls",
        "outputId": "50088388-c7e9-498d-edd8-bd2898ff683e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-d5ef296a-956d-c984-8619-772b012f77d8)\n",
            "Mounted at /content/drive\n",
            "✅ Drive mounted, results will be saved to: /content/drive/MyDrive/vae_cifar10_runs\n",
            "Saving outputs to: /content/drive/MyDrive/vae_cifar10_runs\n",
            "PyTorch: 2.9.0+cu126 | CUDA: True\n",
            "GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Reparameterization ---\n",
        "def reparameterize(mu, logvar):\n",
        "    std = torch.exp(0.5 * logvar)\n",
        "    eps = torch.randn_like(std)\n",
        "    return mu + std * eps\n",
        "\n",
        "# --- Encoder ---\n",
        "class Encoder(nn.Module):\n",
        "    \"\"\"\n",
        "    (B,3,32,32) → (B,256,2,2) via 4× Conv2d(k=4,s=2,p=1)\n",
        "    flatten → 1024 → heads: mu/logvar (B, z_dim)\n",
        "    \"\"\"\n",
        "    def __init__(self, z_dim=128):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 4, 2, 1, bias=False),  # 32x16x16\n",
        "            nn.BatchNorm2d(32), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1, bias=False), # 64x8x8\n",
        "            nn.BatchNorm2d(64), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64,128, 4, 2, 1, bias=False), # 128x4x4\n",
        "            nn.BatchNorm2d(128), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128,256,4, 2, 1, bias=False), # 256x2x2\n",
        "            nn.BatchNorm2d(256), nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc_mu = nn.Linear(256*2*2, z_dim)\n",
        "        self.fc_logvar = nn.Linear(256*2*2, z_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.net(x)\n",
        "        h = self.flatten(h)\n",
        "        mu = self.fc_mu(h)\n",
        "        logvar = self.fc_logvar(h)\n",
        "        return mu, logvar\n",
        "\n",
        "# --- Decoder ---\n",
        "class Decoder(nn.Module):\n",
        "    \"\"\"\n",
        "    z (B,z) → FC 1024 → view (B,256,2,2) → 4× ConvTranspose2d → (B,3,32,32)\n",
        "    \"\"\"\n",
        "    def __init__(self, z_dim=128):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(z_dim, 256*2*2)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256,128,4,2,1,bias=False), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(128,64,4,2,1,bias=False),  nn.BatchNorm2d(64),  nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(64,32,4,2,1,bias=False),   nn.BatchNorm2d(32),  nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(32,3,4,2,1,bias=False),\n",
        "            nn.Tanh(),  # output in [-1,1]\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        h = self.fc(z)\n",
        "        h = h.view(h.size(0), 256, 2, 2)\n",
        "        return self.net(h)\n",
        "\n",
        "# --- VAE wrapper ---\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, z_dim=128):\n",
        "        super().__init__()\n",
        "        self.enc = Encoder(z_dim)\n",
        "        self.dec = Decoder(z_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.enc(x)\n",
        "        z = reparameterize(mu, logvar)\n",
        "        xr = self.dec(z)\n",
        "        return xr, mu, logvar, z\n",
        "\n",
        "# --- Loss ---\n",
        "def vae_loss(x, xr, mu, logvar, recon_type=\"mse\"):\n",
        "    if recon_type == \"mse\":\n",
        "        recon = F.mse_loss(xr, x, reduction=\"mean\")\n",
        "    else:  # BCE expects [0,1]\n",
        "        recon = F.binary_cross_entropy(denorm(xr), denorm(x), reduction=\"mean\")\n",
        "    kl = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return recon, kl\n",
        "\n",
        "# --- DataLoaders (CIFAR-10) ---\n",
        "def get_loaders(cfg):\n",
        "    tfm = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),  # [-1,1]\n",
        "    ])\n",
        "    train = datasets.CIFAR10(cfg.data_root, train=True, download=True, transform=tfm)\n",
        "    test  = datasets.CIFAR10(cfg.data_root, train=False, download=True, transform=tfm)\n",
        "\n",
        "    if cfg.smoke_subset and cfg.smoke_subset > 0:\n",
        "        train = Subset(train, list(range(cfg.smoke_subset)))\n",
        "        test  = Subset(test,  list(range(min(len(test), cfg.smoke_subset//5))))\n",
        "\n",
        "    trainloader = DataLoader(train, batch_size=cfg.batch_size, shuffle=True,\n",
        "                             num_workers=cfg.num_workers, pin_memory=True)\n",
        "    testloader  = DataLoader(test,  batch_size=cfg.batch_size, shuffle=False,\n",
        "                             num_workers=cfg.num_workers, pin_memory=True)\n",
        "    return trainloader, testloader\n",
        "\n",
        "trainloader, testloader = get_loaders(cfg)\n",
        "print(\"Train batches:\", len(trainloader), \"| Test batches:\", len(testloader))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pctp_CF6eQrV",
        "outputId": "8bbeecb2-fcad-456b-efe6-18dbbdd9c0e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:16<00:00, 10.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train batches: 196 | Test batches: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the VAE and save artifacts to Drive\n",
        "vae = VAE(z_dim=cfg.z_dim).to(device)\n",
        "opt = torch.optim.Adam(vae.parameters(), lr=cfg.lr)\n",
        "scaler = torch.cuda.amp.GradScaler(enabled=(cfg.use_amp and device==\"cuda\"))\n",
        "\n",
        "# fixed test batch for recon snapshots\n",
        "vae.eval()\n",
        "with torch.no_grad():\n",
        "    fixed_imgs, _ = next(iter(testloader))\n",
        "fixed_imgs = fixed_imgs[:cfg.grid_n].to(device)\n",
        "vae.train()\n",
        "\n",
        "csv_path = os.path.join(cfg.out_dir, \"train_log.csv\")\n",
        "if not os.path.exists(csv_path):\n",
        "    with open(csv_path, \"w\", newline=\"\") as f:\n",
        "        csv.writer(f).writerow([\"epoch\",\"beta\",\"avg_total\",\"avg_recon\",\"avg_kl\",\"time_sec\"])\n",
        "\n",
        "for epoch in range(1, cfg.epochs + 1):\n",
        "    t0 = time.time()\n",
        "    vae.train()\n",
        "    ep_total = ep_recon = ep_kl = 0.0\n",
        "    beta = beta_schedule(epoch, cfg.beta_warmup_epochs, cfg.beta_start, cfg.beta_end)\n",
        "\n",
        "    for i, (x, _) in enumerate(trainloader, start=1):\n",
        "        x = x.to(device)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(cfg.use_amp and device==\"cuda\")):\n",
        "            xr, mu, logvar, _ = vae(x)\n",
        "            recon, kl = vae_loss(x, xr, mu, logvar, recon_type=\"mse\")\n",
        "            total = recon + beta * kl\n",
        "        scaler.scale(total).backward()\n",
        "        scaler.step(opt)\n",
        "        scaler.update()\n",
        "\n",
        "        ep_total += total.item(); ep_recon += recon.item(); ep_kl += kl.item()\n",
        "        if i % cfg.log_interval == 0:\n",
        "            print(f\"[E{epoch:03d} {i:04d}/{len(trainloader)}] β={beta:.3f} total={total.item():.4f} recon={recon.item():.4f} kl={kl.item():.4f}\")\n",
        "\n",
        "    # epoch summary\n",
        "    n = len(trainloader); dt = time.time() - t0\n",
        "    avg_total, avg_recon, avg_kl = ep_total/n, ep_recon/n, ep_kl/n\n",
        "    print(f\"==> Epoch {epoch} | β={beta:.3f} | {dt:.1f}s | total={avg_total:.4f} recon={avg_recon:.4f} kl={avg_kl:.4f}\")\n",
        "    with open(csv_path, \"a\", newline=\"\") as f:\n",
        "        csv.writer(f).writerow([epoch, beta, avg_total, avg_recon, avg_kl, round(dt,2)])\n",
        "\n",
        "    # save recon grid (originals top, recon bottom)\n",
        "    vae.eval()\n",
        "    with torch.no_grad():\n",
        "        xr, _, _, _ = vae(fixed_imgs)\n",
        "    save_grid_pair(fixed_imgs, xr, os.path.join(cfg.out_dir, f\"recon_epoch_{epoch:03d}.png\"), nrow=8)\n",
        "\n",
        "    # save random samples grid\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(cfg.grid_n, cfg.z_dim, device=device)\n",
        "        xs = vae.dec(z)\n",
        "    vutils.save_image(vutils.make_grid(denorm(xs), nrow=8),\n",
        "                      os.path.join(cfg.out_dir, f\"samples_epoch_{epoch:03d}.png\"))\n",
        "\n",
        "    # checkpoint\n",
        "    ckpt = {\"epoch\": epoch, \"model\": vae.state_dict(), \"optimizer\": opt.state_dict(),\n",
        "            \"cfg\": cfg.__dict__}\n",
        "    torch.save(ckpt, os.path.join(cfg.out_dir, f\"vae_epoch_{epoch:03d}.pth\"))\n",
        "\n",
        "print(\"Training complete. Outputs in:\", cfg.out_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WawquNyoekxR",
        "outputId": "c5ada51c-fd63-441c-88c6-dde4140c101a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1817000089.py:4: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = torch.cuda.amp.GradScaler(enabled=(cfg.use_amp and device==\"cuda\"))\n",
            "/tmp/ipython-input-1817000089.py:27: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast(enabled=(cfg.use_amp and device==\"cuda\")):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[E001 0100/196] β=0.100 total=0.1191 recon=0.1048 kl=0.1428\n",
            "==> Epoch 1 | β=0.100 | 14.5s | total=0.1346 recon=0.1206 kl=0.1406\n",
            "[E002 0100/196] β=0.200 total=0.0994 recon=0.0784 kl=0.1049\n",
            "==> Epoch 2 | β=0.200 | 13.8s | total=0.1024 recon=0.0810 kl=0.1070\n",
            "[E003 0100/196] β=0.300 total=0.1074 recon=0.0812 kl=0.0872\n",
            "==> Epoch 3 | β=0.300 | 12.2s | total=0.1037 recon=0.0776 kl=0.0867\n",
            "[E004 0100/196] β=0.400 total=0.1093 recon=0.0791 kl=0.0755\n",
            "==> Epoch 4 | β=0.400 | 11.3s | total=0.1096 recon=0.0804 kl=0.0731\n",
            "[E005 0100/196] β=0.500 total=0.1149 recon=0.0842 kl=0.0613\n",
            "==> Epoch 5 | β=0.500 | 11.4s | total=0.1149 recon=0.0836 kl=0.0627\n",
            "[E006 0100/196] β=0.600 total=0.1177 recon=0.0851 kl=0.0543\n",
            "==> Epoch 6 | β=0.600 | 12.1s | total=0.1200 recon=0.0870 kl=0.0549\n",
            "[E007 0100/196] β=0.700 total=0.1242 recon=0.0894 kl=0.0497\n",
            "==> Epoch 7 | β=0.700 | 12.0s | total=0.1248 recon=0.0907 kl=0.0488\n",
            "[E008 0100/196] β=0.800 total=0.1300 recon=0.0949 kl=0.0439\n",
            "==> Epoch 8 | β=0.800 | 12.1s | total=0.1288 recon=0.0936 kl=0.0440\n",
            "[E009 0100/196] β=0.900 total=0.1224 recon=0.0877 kl=0.0386\n",
            "==> Epoch 9 | β=0.900 | 12.1s | total=0.1327 recon=0.0968 kl=0.0399\n",
            "[E010 0100/196] β=1.000 total=0.1381 recon=0.1002 kl=0.0378\n",
            "==> Epoch 10 | β=1.000 | 12.2s | total=0.1363 recon=0.0999 kl=0.0364\n",
            "[E011 0100/196] β=1.000 total=0.1396 recon=0.1014 kl=0.0382\n",
            "==> Epoch 11 | β=1.000 | 11.2s | total=0.1359 recon=0.0997 kl=0.0362\n",
            "[E012 0100/196] β=1.000 total=0.1353 recon=0.0989 kl=0.0364\n",
            "==> Epoch 12 | β=1.000 | 11.5s | total=0.1357 recon=0.0997 kl=0.0360\n",
            "[E013 0100/196] β=1.000 total=0.1282 recon=0.0958 kl=0.0323\n",
            "==> Epoch 13 | β=1.000 | 12.1s | total=0.1353 recon=0.0995 kl=0.0359\n",
            "[E014 0100/196] β=1.000 total=0.1378 recon=0.1008 kl=0.0370\n",
            "==> Epoch 14 | β=1.000 | 12.0s | total=0.1353 recon=0.0993 kl=0.0360\n",
            "[E015 0100/196] β=1.000 total=0.1348 recon=0.0995 kl=0.0353\n",
            "==> Epoch 15 | β=1.000 | 12.1s | total=0.1351 recon=0.0993 kl=0.0358\n",
            "[E016 0100/196] β=1.000 total=0.1421 recon=0.1047 kl=0.0374\n",
            "==> Epoch 16 | β=1.000 | 12.0s | total=0.1350 recon=0.0991 kl=0.0359\n",
            "[E017 0100/196] β=1.000 total=0.1386 recon=0.1037 kl=0.0349\n",
            "==> Epoch 17 | β=1.000 | 12.2s | total=0.1349 recon=0.0991 kl=0.0359\n",
            "[E018 0100/196] β=1.000 total=0.1365 recon=0.1010 kl=0.0355\n",
            "==> Epoch 18 | β=1.000 | 11.8s | total=0.1347 recon=0.0988 kl=0.0359\n",
            "[E019 0100/196] β=1.000 total=0.1406 recon=0.1041 kl=0.0366\n",
            "==> Epoch 19 | β=1.000 | 11.1s | total=0.1346 recon=0.0988 kl=0.0358\n",
            "[E020 0100/196] β=1.000 total=0.1379 recon=0.1011 kl=0.0369\n",
            "==> Epoch 20 | β=1.000 | 12.0s | total=0.1347 recon=0.0989 kl=0.0358\n",
            "[E021 0100/196] β=1.000 total=0.1359 recon=0.1006 kl=0.0353\n",
            "==> Epoch 21 | β=1.000 | 12.2s | total=0.1345 recon=0.0987 kl=0.0359\n",
            "[E022 0100/196] β=1.000 total=0.1323 recon=0.0947 kl=0.0376\n",
            "==> Epoch 22 | β=1.000 | 12.1s | total=0.1345 recon=0.0986 kl=0.0359\n",
            "[E023 0100/196] β=1.000 total=0.1323 recon=0.0977 kl=0.0346\n",
            "==> Epoch 23 | β=1.000 | 11.8s | total=0.1345 recon=0.0986 kl=0.0358\n",
            "[E024 0100/196] β=1.000 total=0.1397 recon=0.1059 kl=0.0339\n",
            "==> Epoch 24 | β=1.000 | 12.0s | total=0.1343 recon=0.0984 kl=0.0359\n",
            "[E025 0100/196] β=1.000 total=0.1343 recon=0.0977 kl=0.0365\n",
            "==> Epoch 25 | β=1.000 | 11.0s | total=0.1342 recon=0.0982 kl=0.0359\n",
            "[E026 0100/196] β=1.000 total=0.1371 recon=0.1007 kl=0.0364\n",
            "==> Epoch 26 | β=1.000 | 10.9s | total=0.1340 recon=0.0982 kl=0.0358\n",
            "[E027 0100/196] β=1.000 total=0.1373 recon=0.0999 kl=0.0374\n",
            "==> Epoch 27 | β=1.000 | 12.1s | total=0.1342 recon=0.0983 kl=0.0359\n",
            "[E028 0100/196] β=1.000 total=0.1324 recon=0.0967 kl=0.0357\n",
            "==> Epoch 28 | β=1.000 | 12.7s | total=0.1341 recon=0.0982 kl=0.0359\n",
            "[E029 0100/196] β=1.000 total=0.1367 recon=0.1016 kl=0.0351\n",
            "==> Epoch 29 | β=1.000 | 11.5s | total=0.1340 recon=0.0981 kl=0.0359\n",
            "[E030 0100/196] β=1.000 total=0.1312 recon=0.0956 kl=0.0357\n",
            "==> Epoch 30 | β=1.000 | 11.4s | total=0.1338 recon=0.0979 kl=0.0359\n",
            "[E031 0100/196] β=1.000 total=0.1299 recon=0.0945 kl=0.0355\n",
            "==> Epoch 31 | β=1.000 | 11.7s | total=0.1339 recon=0.0980 kl=0.0359\n",
            "[E032 0100/196] β=1.000 total=0.1333 recon=0.0974 kl=0.0359\n",
            "==> Epoch 32 | β=1.000 | 10.1s | total=0.1339 recon=0.0979 kl=0.0359\n",
            "[E033 0100/196] β=1.000 total=0.1386 recon=0.0993 kl=0.0393\n",
            "==> Epoch 33 | β=1.000 | 11.1s | total=0.1338 recon=0.0978 kl=0.0360\n",
            "[E034 0100/196] β=1.000 total=0.1312 recon=0.0947 kl=0.0365\n",
            "==> Epoch 34 | β=1.000 | 11.6s | total=0.1336 recon=0.0976 kl=0.0360\n",
            "[E035 0100/196] β=1.000 total=0.1363 recon=0.1004 kl=0.0359\n",
            "==> Epoch 35 | β=1.000 | 11.4s | total=0.1337 recon=0.0977 kl=0.0360\n",
            "[E036 0100/196] β=1.000 total=0.1352 recon=0.0991 kl=0.0360\n",
            "==> Epoch 36 | β=1.000 | 11.6s | total=0.1336 recon=0.0976 kl=0.0360\n",
            "[E037 0100/196] β=1.000 total=0.1354 recon=0.0996 kl=0.0358\n",
            "==> Epoch 37 | β=1.000 | 11.1s | total=0.1335 recon=0.0975 kl=0.0360\n",
            "[E038 0100/196] β=1.000 total=0.1316 recon=0.0970 kl=0.0346\n",
            "==> Epoch 38 | β=1.000 | 10.6s | total=0.1335 recon=0.0975 kl=0.0360\n",
            "[E039 0100/196] β=1.000 total=0.1302 recon=0.0951 kl=0.0351\n",
            "==> Epoch 39 | β=1.000 | 11.6s | total=0.1334 recon=0.0974 kl=0.0360\n",
            "[E040 0100/196] β=1.000 total=0.1361 recon=0.1002 kl=0.0359\n",
            "==> Epoch 40 | β=1.000 | 11.6s | total=0.1335 recon=0.0974 kl=0.0361\n",
            "[E041 0100/196] β=1.000 total=0.1288 recon=0.0930 kl=0.0358\n",
            "==> Epoch 41 | β=1.000 | 11.5s | total=0.1334 recon=0.0974 kl=0.0360\n",
            "[E042 0100/196] β=1.000 total=0.1297 recon=0.0934 kl=0.0363\n",
            "==> Epoch 42 | β=1.000 | 11.6s | total=0.1331 recon=0.0972 kl=0.0359\n",
            "[E043 0100/196] β=1.000 total=0.1334 recon=0.0976 kl=0.0358\n",
            "==> Epoch 43 | β=1.000 | 10.6s | total=0.1333 recon=0.0973 kl=0.0360\n",
            "[E044 0100/196] β=1.000 total=0.1352 recon=0.0994 kl=0.0358\n",
            "==> Epoch 44 | β=1.000 | 10.7s | total=0.1333 recon=0.0973 kl=0.0360\n",
            "[E045 0100/196] β=1.000 total=0.1339 recon=0.0978 kl=0.0360\n",
            "==> Epoch 45 | β=1.000 | 11.3s | total=0.1331 recon=0.0971 kl=0.0360\n",
            "[E046 0100/196] β=1.000 total=0.1360 recon=0.0989 kl=0.0370\n",
            "==> Epoch 46 | β=1.000 | 11.4s | total=0.1333 recon=0.0972 kl=0.0361\n",
            "[E047 0100/196] β=1.000 total=0.1371 recon=0.1008 kl=0.0363\n",
            "==> Epoch 47 | β=1.000 | 11.5s | total=0.1332 recon=0.0971 kl=0.0361\n",
            "[E048 0100/196] β=1.000 total=0.1354 recon=0.0991 kl=0.0363\n",
            "==> Epoch 48 | β=1.000 | 10.9s | total=0.1331 recon=0.0969 kl=0.0362\n",
            "[E049 0100/196] β=1.000 total=0.1372 recon=0.0995 kl=0.0377\n",
            "==> Epoch 49 | β=1.000 | 10.3s | total=0.1332 recon=0.0969 kl=0.0363\n",
            "[E050 0100/196] β=1.000 total=0.1316 recon=0.0946 kl=0.0369\n",
            "==> Epoch 50 | β=1.000 | 11.4s | total=0.1332 recon=0.0969 kl=0.0362\n",
            "[E051 0100/196] β=1.000 total=0.1324 recon=0.0975 kl=0.0349\n",
            "==> Epoch 51 | β=1.000 | 11.3s | total=0.1330 recon=0.0969 kl=0.0361\n",
            "[E052 0100/196] β=1.000 total=0.1357 recon=0.1000 kl=0.0357\n",
            "==> Epoch 52 | β=1.000 | 11.2s | total=0.1330 recon=0.0968 kl=0.0362\n",
            "[E053 0100/196] β=1.000 total=0.1311 recon=0.0948 kl=0.0363\n",
            "==> Epoch 53 | β=1.000 | 11.2s | total=0.1331 recon=0.0969 kl=0.0362\n",
            "[E054 0100/196] β=1.000 total=0.1321 recon=0.0961 kl=0.0360\n",
            "==> Epoch 54 | β=1.000 | 10.1s | total=0.1329 recon=0.0967 kl=0.0362\n",
            "[E055 0100/196] β=1.000 total=0.1317 recon=0.0963 kl=0.0354\n",
            "==> Epoch 55 | β=1.000 | 16.4s | total=0.1329 recon=0.0968 kl=0.0361\n",
            "[E056 0100/196] β=1.000 total=0.1306 recon=0.0939 kl=0.0368\n",
            "==> Epoch 56 | β=1.000 | 10.7s | total=0.1328 recon=0.0966 kl=0.0362\n",
            "[E057 0100/196] β=1.000 total=0.1295 recon=0.0932 kl=0.0364\n",
            "==> Epoch 57 | β=1.000 | 11.3s | total=0.1329 recon=0.0967 kl=0.0362\n",
            "[E058 0100/196] β=1.000 total=0.1346 recon=0.0984 kl=0.0362\n",
            "==> Epoch 58 | β=1.000 | 11.4s | total=0.1328 recon=0.0966 kl=0.0362\n",
            "[E059 0100/196] β=1.000 total=0.1335 recon=0.0952 kl=0.0383\n",
            "==> Epoch 59 | β=1.000 | 11.3s | total=0.1328 recon=0.0966 kl=0.0362\n",
            "[E060 0100/196] β=1.000 total=0.1348 recon=0.0989 kl=0.0359\n",
            "==> Epoch 60 | β=1.000 | 10.8s | total=0.1327 recon=0.0965 kl=0.0361\n",
            "[E061 0100/196] β=1.000 total=0.1295 recon=0.0939 kl=0.0356\n",
            "==> Epoch 61 | β=1.000 | 10.5s | total=0.1329 recon=0.0966 kl=0.0362\n",
            "[E062 0100/196] β=1.000 total=0.1322 recon=0.0952 kl=0.0369\n",
            "==> Epoch 62 | β=1.000 | 12.3s | total=0.1328 recon=0.0965 kl=0.0363\n",
            "[E063 0100/196] β=1.000 total=0.1300 recon=0.0940 kl=0.0360\n",
            "==> Epoch 63 | β=1.000 | 11.6s | total=0.1326 recon=0.0964 kl=0.0362\n",
            "[E064 0100/196] β=1.000 total=0.1364 recon=0.0996 kl=0.0367\n",
            "==> Epoch 64 | β=1.000 | 11.6s | total=0.1327 recon=0.0965 kl=0.0362\n",
            "[E065 0100/196] β=1.000 total=0.1312 recon=0.0948 kl=0.0364\n",
            "==> Epoch 65 | β=1.000 | 11.6s | total=0.1327 recon=0.0965 kl=0.0362\n",
            "[E066 0100/196] β=1.000 total=0.1342 recon=0.0983 kl=0.0359\n",
            "==> Epoch 66 | β=1.000 | 11.7s | total=0.1327 recon=0.0964 kl=0.0363\n",
            "[E067 0100/196] β=1.000 total=0.1325 recon=0.0981 kl=0.0344\n",
            "==> Epoch 67 | β=1.000 | 10.4s | total=0.1327 recon=0.0964 kl=0.0363\n",
            "[E068 0100/196] β=1.000 total=0.1302 recon=0.0940 kl=0.0362\n",
            "==> Epoch 68 | β=1.000 | 11.4s | total=0.1327 recon=0.0964 kl=0.0363\n",
            "[E069 0100/196] β=1.000 total=0.1342 recon=0.1000 kl=0.0342\n",
            "==> Epoch 69 | β=1.000 | 11.6s | total=0.1327 recon=0.0964 kl=0.0363\n",
            "[E070 0100/196] β=1.000 total=0.1353 recon=0.0986 kl=0.0368\n",
            "==> Epoch 70 | β=1.000 | 11.4s | total=0.1327 recon=0.0963 kl=0.0363\n",
            "[E071 0100/196] β=1.000 total=0.1284 recon=0.0921 kl=0.0363\n",
            "==> Epoch 71 | β=1.000 | 11.6s | total=0.1325 recon=0.0962 kl=0.0364\n",
            "[E072 0100/196] β=1.000 total=0.1317 recon=0.0952 kl=0.0365\n",
            "==> Epoch 72 | β=1.000 | 11.6s | total=0.1325 recon=0.0963 kl=0.0363\n",
            "[E073 0100/196] β=1.000 total=0.1391 recon=0.1020 kl=0.0370\n",
            "==> Epoch 73 | β=1.000 | 10.3s | total=0.1326 recon=0.0962 kl=0.0364\n",
            "[E074 0100/196] β=1.000 total=0.1320 recon=0.0961 kl=0.0359\n",
            "==> Epoch 74 | β=1.000 | 11.4s | total=0.1325 recon=0.0962 kl=0.0363\n",
            "[E075 0100/196] β=1.000 total=0.1325 recon=0.0950 kl=0.0376\n",
            "==> Epoch 75 | β=1.000 | 11.4s | total=0.1324 recon=0.0961 kl=0.0363\n",
            "[E076 0100/196] β=1.000 total=0.1290 recon=0.0933 kl=0.0357\n",
            "==> Epoch 76 | β=1.000 | 11.5s | total=0.1323 recon=0.0960 kl=0.0363\n",
            "[E077 0100/196] β=1.000 total=0.1273 recon=0.0904 kl=0.0368\n",
            "==> Epoch 77 | β=1.000 | 11.4s | total=0.1324 recon=0.0961 kl=0.0363\n",
            "[E078 0100/196] β=1.000 total=0.1347 recon=0.0973 kl=0.0375\n",
            "==> Epoch 78 | β=1.000 | 11.1s | total=0.1325 recon=0.0961 kl=0.0364\n",
            "[E079 0100/196] β=1.000 total=0.1316 recon=0.0946 kl=0.0370\n",
            "==> Epoch 79 | β=1.000 | 10.3s | total=0.1324 recon=0.0960 kl=0.0364\n",
            "[E080 0100/196] β=1.000 total=0.1302 recon=0.0945 kl=0.0357\n",
            "==> Epoch 80 | β=1.000 | 11.4s | total=0.1323 recon=0.0959 kl=0.0364\n",
            "[E081 0100/196] β=1.000 total=0.1323 recon=0.0970 kl=0.0353\n",
            "==> Epoch 81 | β=1.000 | 12.5s | total=0.1323 recon=0.0960 kl=0.0363\n",
            "[E082 0100/196] β=1.000 total=0.1331 recon=0.0963 kl=0.0368\n",
            "==> Epoch 82 | β=1.000 | 12.0s | total=0.1324 recon=0.0960 kl=0.0364\n",
            "[E083 0100/196] β=1.000 total=0.1296 recon=0.0939 kl=0.0357\n",
            "==> Epoch 83 | β=1.000 | 11.6s | total=0.1324 recon=0.0960 kl=0.0364\n",
            "[E084 0100/196] β=1.000 total=0.1334 recon=0.0960 kl=0.0374\n",
            "==> Epoch 84 | β=1.000 | 11.8s | total=0.1323 recon=0.0959 kl=0.0364\n",
            "[E085 0100/196] β=1.000 total=0.1353 recon=0.0990 kl=0.0363\n",
            "==> Epoch 85 | β=1.000 | 11.3s | total=0.1323 recon=0.0959 kl=0.0364\n",
            "[E086 0100/196] β=1.000 total=0.1386 recon=0.1018 kl=0.0368\n",
            "==> Epoch 86 | β=1.000 | 10.6s | total=0.1323 recon=0.0959 kl=0.0364\n",
            "[E087 0100/196] β=1.000 total=0.1305 recon=0.0949 kl=0.0356\n",
            "==> Epoch 87 | β=1.000 | 11.7s | total=0.1322 recon=0.0958 kl=0.0364\n",
            "[E088 0100/196] β=1.000 total=0.1310 recon=0.0955 kl=0.0355\n",
            "==> Epoch 88 | β=1.000 | 11.7s | total=0.1323 recon=0.0958 kl=0.0364\n",
            "[E089 0100/196] β=1.000 total=0.1337 recon=0.0965 kl=0.0373\n",
            "==> Epoch 89 | β=1.000 | 11.7s | total=0.1320 recon=0.0956 kl=0.0364\n",
            "[E090 0100/196] β=1.000 total=0.1307 recon=0.0941 kl=0.0366\n",
            "==> Epoch 90 | β=1.000 | 11.6s | total=0.1323 recon=0.0958 kl=0.0365\n",
            "[E091 0100/196] β=1.000 total=0.1349 recon=0.0980 kl=0.0368\n",
            "==> Epoch 91 | β=1.000 | 11.3s | total=0.1323 recon=0.0959 kl=0.0364\n",
            "[E092 0100/196] β=1.000 total=0.1262 recon=0.0909 kl=0.0353\n",
            "==> Epoch 92 | β=1.000 | 10.4s | total=0.1321 recon=0.0957 kl=0.0364\n",
            "[E093 0100/196] β=1.000 total=0.1317 recon=0.0970 kl=0.0347\n",
            "==> Epoch 93 | β=1.000 | 11.4s | total=0.1322 recon=0.0957 kl=0.0365\n",
            "[E094 0100/196] β=1.000 total=0.1352 recon=0.0981 kl=0.0372\n",
            "==> Epoch 94 | β=1.000 | 11.7s | total=0.1322 recon=0.0958 kl=0.0364\n",
            "[E095 0100/196] β=1.000 total=0.1388 recon=0.1019 kl=0.0370\n",
            "==> Epoch 95 | β=1.000 | 11.6s | total=0.1321 recon=0.0957 kl=0.0365\n",
            "[E096 0100/196] β=1.000 total=0.1319 recon=0.0964 kl=0.0355\n",
            "==> Epoch 96 | β=1.000 | 11.8s | total=0.1320 recon=0.0956 kl=0.0364\n",
            "[E097 0100/196] β=1.000 total=0.1329 recon=0.0977 kl=0.0352\n",
            "==> Epoch 97 | β=1.000 | 11.2s | total=0.1321 recon=0.0956 kl=0.0365\n",
            "[E098 0100/196] β=1.000 total=0.1318 recon=0.0951 kl=0.0368\n",
            "==> Epoch 98 | β=1.000 | 10.2s | total=0.1320 recon=0.0956 kl=0.0364\n",
            "[E099 0100/196] β=1.000 total=0.1311 recon=0.0953 kl=0.0358\n",
            "==> Epoch 99 | β=1.000 | 11.5s | total=0.1320 recon=0.0955 kl=0.0365\n",
            "[E100 0100/196] β=1.000 total=0.1368 recon=0.0993 kl=0.0375\n",
            "==> Epoch 100 | β=1.000 | 11.7s | total=0.1321 recon=0.0956 kl=0.0366\n",
            "Training complete. Outputs in: /content/drive/MyDrive/vae_cifar10_runs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "export_dir = os.path.join(cfg.out_dir, \"samples_10k\")\n",
        "os.makedirs(export_dir, exist_ok=True)\n",
        "vae.eval()\n",
        "\n",
        "saved = 0\n",
        "with torch.no_grad():\n",
        "    while saved < cfg.samples_export_total:\n",
        "        cur = min(cfg.samples_export_bs, cfg.samples_export_total - saved)\n",
        "        z = torch.randn(cur, cfg.z_dim, device=device)\n",
        "        xs = denorm(vae.dec(z))\n",
        "        for i in range(cur):\n",
        "            vutils.save_image(xs[i], os.path.join(export_dir, f\"sample_{saved+i:05d}.png\"))\n",
        "        saved += cur\n",
        "\n",
        "print(f\"Saved {saved} samples to {export_dir}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSQQUVUuevDW",
        "outputId": "6327e670-397e-4924-b0ba-9ec7459118b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 10000 samples to /content/drive/MyDrive/vae_cifar10_runs/samples_10k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Vary one latent dimension while keeping others fixed\n",
        "tfm = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
        "])\n",
        "test_only = datasets.CIFAR10(cfg.data_root, train=False, download=True, transform=tfm)\n",
        "x0, _ = test_only[0]\n",
        "x0 = x0.unsqueeze(0).to(device)\n",
        "\n",
        "vae.eval()\n",
        "with torch.no_grad():\n",
        "    mu, logvar = vae.enc(x0)\n",
        "    base = mu[0].clone()\n",
        "    vals = torch.linspace(-3, 3, 13, device=device)\n",
        "    imgs = []\n",
        "    dim = 0  # change the latent dimension to traverse\n",
        "    for v in vals:\n",
        "        z = base.clone(); z[dim] = v\n",
        "        img = vae.dec(z.unsqueeze(0))\n",
        "        imgs.append(denorm(img))\n",
        "    grid = vutils.make_grid(torch.cat(imgs, dim=0), nrow=len(vals))\n",
        "    out_path = os.path.join(cfg.out_dir, \"latent_traversal_dim0.png\")\n",
        "    vutils.save_image(grid, out_path)\n",
        "out_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HW8gEmp3ezHo",
        "outputId": "53825062-04a0-4400-df03-2f8464f3ddfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/vae_cifar10_runs/latent_traversal_dim0.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === FID & IS in one go ===\n",
        "# - Computes FID between CIFAR-10 test set and your generated samples (10k recommended)\n",
        "# - Computes Inception Score on your generated samples\n",
        "# - Saves results to metrics.txt in your Drive run folder\n",
        "\n",
        "# 1) Install deps\n",
        "!pip -q install pytorch-fid torchmetrics torch-fidelity\n",
        "\n",
        "import os, math\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "from torchvision import datasets\n",
        "from pytorch_fid import fid_score\n",
        "from torchmetrics.image.inception import InceptionScore\n",
        "import torch, os\n",
        "from torch_fidelity import calculate_metrics\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# 2) Paths (edit GEN_DIR if you used a different folder)\n",
        "RUN_DIR = \"/content/drive/MyDrive/vae_cifar10_runs\"\n",
        "GEN_DIR = os.path.join(RUN_DIR, \"samples_10k\")   # generated images you exported\n",
        "REAL_DIR = \"/content/cifar10_real_test\"          # will be created once for CIFAR-10 test imgs\n",
        "os.makedirs(RUN_DIR, exist_ok=True)\n",
        "os.makedirs(REAL_DIR, exist_ok=True)\n",
        "\n",
        "# 3) Prepare REAL CIFAR-10 (test set) as PNGs if not already\n",
        "#    We save raw test images with no normalization (PIL) for a fair FID reference.\n",
        "if len([f for f in os.listdir(REAL_DIR) if f.endswith(\".png\")]) < 10000:\n",
        "    print(\"Preparing CIFAR-10 test images (first time only)...\")\n",
        "    real_ds = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=None)\n",
        "    for i in range(len(real_ds)):\n",
        "        img, _ = real_ds[i]            # PIL Image\n",
        "        img.save(f\"{REAL_DIR}/{i:05d}.png\")\n",
        "    print(\"Saved CIFAR-10 test images to:\", REAL_DIR)\n",
        "else:\n",
        "    print(\"Found existing CIFAR-10 test images in:\", REAL_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVzICW1Ft6uj",
        "outputId": "aeae7d4e-3823-4809-aefa-122478301514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/983.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hPreparing CIFAR-10 test images (first time only)...\n",
            "Saved CIFAR-10 test images to: /content/cifar10_real_test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4) Compute FID (lower is better)\n",
        "assert os.path.isdir(GEN_DIR) and len(os.listdir(GEN_DIR)) > 0, f\"No generated images found at: {GEN_DIR}\"\n",
        "fid = fid_score.calculate_fid_given_paths(\n",
        "    [REAL_DIR, GEN_DIR],\n",
        "    batch_size=64,\n",
        "    device=device,\n",
        "    dims=2048\n",
        ")\n",
        "print(f\"\\nFID: {fid:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zIEtfPhH5jn",
        "outputId": "361c9951-08ac-4458-b8a3-f181205e4c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/mseitzer/pytorch-fid/releases/download/fid_weights/pt_inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/pt_inception-2015-12-05-6726825d.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 91.2M/91.2M [00:00<00:00, 285MB/s]\n",
            "100%|██████████| 157/157 [00:41<00:00,  3.80it/s]\n",
            "100%|██████████| 157/157 [02:14<00:00,  1.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "FID: 240.41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5) Compute Inception Score (higher is better)\n",
        "#    Torchmetrics expects tensors in [0,1] with shape (B,3,H,W). We’ll just load your PNGs.\n",
        "from torchvision.transforms import InterpolationMode\n",
        "\n",
        "class FolderDataset(Dataset):\n",
        "    def __init__(self, path):\n",
        "        self.files = [os.path.join(path, f) for f in os.listdir(path) if f.endswith(\".png\")]\n",
        "        self.files.sort()\n",
        "        # Keep uint8 [0,255] tensors\n",
        "        self.tf = T.Compose([\n",
        "            T.Resize(299, interpolation=InterpolationMode.BILINEAR),\n",
        "            T.CenterCrop(299),\n",
        "            T.PILToTensor(),     # <- uint8, shape (C,H,W)\n",
        "        ])\n",
        "    def __len__(self):\n",
        "        return len(self.files)\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.files[idx]).convert(\"RGB\")\n",
        "        return self.tf(img)\n",
        "\n",
        "\n",
        "gen_ds = FolderDataset(GEN_DIR)\n",
        "gen_loader = DataLoader(gen_ds, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "is_metric = InceptionScore(splits=10).to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in gen_loader:\n",
        "        batch = batch.to(device)          # uint8 [0,255]\n",
        "        is_metric.update(batch)\n",
        "\n",
        "is_mean, is_std = is_metric.compute()\n",
        "print(f\"Inception Score: {is_mean:.2f} ± {is_std:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ffe_k-xUH8aX",
        "outputId": "44ee84b0-1edd-45ad-df69-f3c179c187bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `InceptionScore` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Downloading: \"https://github.com/toshas/torch-fidelity/releases/download/v0.2.0/weights-inception-2015-12-05-6726825d.pth\" to /root/.cache/torch/hub/checkpoints/weights-inception-2015-12-05-6726825d.pth\n",
            "100%|██████████| 91.2M/91.2M [00:02<00:00, 40.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inception Score: 1.98 ± 0.04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import InterpolationMode\n",
        "from torchmetrics.image.kid import KernelInceptionDistance\n",
        "\n",
        "class FolderDatasetUint8(Dataset):\n",
        "    def __init__(self, path):\n",
        "        self.files = [os.path.join(path, f) for f in os.listdir(path) if f.endswith(\".png\")]\n",
        "        self.files.sort()\n",
        "        self.tf = T.Compose([\n",
        "            T.Resize(299, interpolation=InterpolationMode.BILINEAR),\n",
        "            T.CenterCrop(299),\n",
        "            T.PILToTensor(),        # -> uint8 [0,255], CxHxW\n",
        "        ])\n",
        "    def __len__(self): return len(self.files)\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.files[idx]).convert(\"RGB\")\n",
        "        return self.tf(img)\n",
        "\n",
        "real_ds = FolderDatasetUint8(REAL_DIR)\n",
        "gen_ds  = FolderDatasetUint8(GEN_DIR)\n",
        "\n",
        "real_loader = DataLoader(real_ds, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "gen_loader  = DataLoader(gen_ds,  batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "kid_metric = KernelInceptionDistance(subset_size=1000).to(device)  # subset_size<=num_images\n",
        "\n",
        "with torch.no_grad():\n",
        "    # real images\n",
        "    for batch in real_loader:\n",
        "        batch = batch.to(device)\n",
        "        kid_metric.update(batch, real=True)\n",
        "    # generated images\n",
        "    for batch in gen_loader:\n",
        "        batch = batch.to(device)\n",
        "        kid_metric.update(batch, real=False)\n",
        "\n",
        "kid_mean, kid_std = kid_metric.compute()\n",
        "print(f\"KID: {kid_mean.item():.4f} ± {kid_std.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGZDNpjfJoP2",
        "outputId": "c0d67eeb-6e5c-40b9-98ec-7c887176f1a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchmetrics/utilities/prints.py:43: UserWarning: Metric `Kernel Inception Distance` will save all extracted features in buffer. For large datasets this may lead to large memory footprint.\n",
            "  warnings.warn(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KID: 0.2471 ± 0.0039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 6) Save results to Drive\n",
        "with open(os.path.join(RUN_DIR, \"metrics.txt\"), \"w\") as f:\n",
        "    f.write(f\"FID: {fid:.2f}\\n\")\n",
        "    f.write(f\"Inception Score: {is_mean:.2f} ± {is_std:.2f}\\n\")\n",
        "    f.write(f\"KID: {kid_mean:.6f} ± {kid_std:.6f}\\n\")\n",
        "\n",
        "print(\"\\nSaved metrics to:\", os.path.join(RUN_DIR, \"metrics.txt\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9u_l1Q_YH_mr",
        "outputId": "283f439b-7199-4479-c3e4-b25d75daf2f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saved metrics to: /content/drive/MyDrive/vae_cifar10_runs/metrics.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Generate Later: load checkpoint and sample images ---\n",
        "import os, torch\n",
        "from torchvision.utils import save_image\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "CKPT_DIR = \"/content/drive/MyDrive/vae_cifar10_runs\"     # folder you used before\n",
        "CKPT_FILE = \"vae_epoch_050.pth\"                           # choose a saved checkpoint\n",
        "\n",
        "# --- Rebuild model definitions (same as before) ---\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "def denorm(x): return (x.clamp(-1,1) + 1) / 2\n",
        "\n",
        "def reparameterize(mu, logvar):\n",
        "    std = torch.exp(0.5 * logvar); eps = torch.randn_like(std)\n",
        "    return mu + std * eps\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, z_dim=128):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 4, 2, 1, bias=False), nn.BatchNorm2d(32), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(32, 64, 4, 2, 1, bias=False), nn.BatchNorm2d(64), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64,128, 4, 2, 1, bias=False), nn.BatchNorm2d(128), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128,256,4, 2, 1, bias=False), nn.BatchNorm2d(256), nn.LeakyReLU(0.2, inplace=True),\n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc_mu = nn.Linear(256*2*2, z_dim)\n",
        "        self.fc_logvar = nn.Linear(256*2*2, z_dim)\n",
        "    def forward(self, x):\n",
        "        h = self.net(x); h = self.flatten(h)\n",
        "        return self.fc_mu(h), self.fc_logvar(h)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, z_dim=128):\n",
        "        super().__init__()\n",
        "        self.fc = nn.Linear(z_dim, 256*2*2)\n",
        "        self.net = nn.Sequential(\n",
        "            nn.ConvTranspose2d(256,128,4,2,1,bias=False), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(128,64,4,2,1,bias=False),  nn.BatchNorm2d(64),  nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(64,32,4,2,1,bias=False),   nn.BatchNorm2d(32),  nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(32,3,4,2,1,bias=False),    nn.Tanh(),\n",
        "        )\n",
        "    def forward(self, z):\n",
        "        h = self.fc(z); h = h.view(h.size(0),256,2,2)\n",
        "        return self.net(h)\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, z_dim=128):\n",
        "        super().__init__(); self.enc = Encoder(z_dim); self.dec = Decoder(z_dim)\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.enc(x); z = reparameterize(mu, logvar); xr = self.dec(z)\n",
        "        return xr, mu, logvar, z\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "ckpt = torch.load(os.path.join(CKPT_DIR, CKPT_FILE), map_location=device)\n",
        "\n",
        "z_dim = ckpt[\"cfg\"][\"z_dim\"]\n",
        "vae = VAE(z_dim=z_dim).to(device)\n",
        "vae.load_state_dict(ckpt[\"model\"])\n",
        "vae.eval()\n",
        "\n",
        "# Generate 64 samples and save a grid to Drive\n",
        "with torch.no_grad():\n",
        "    z = torch.randn(64, z_dim, device=device)\n",
        "    xs = vae.dec(z)\n",
        "grid_path = os.path.join(CKPT_DIR, \"samples_from_loaded.png\")\n",
        "vutils.save_image(vutils.make_grid(denorm(xs), nrow=8), grid_path)\n",
        "print(\"Saved:\", grid_path)\n"
      ],
      "metadata": {
        "id": "_NE_e1Lye1g0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6981beb-7c85-4c75-b9c1-eeda75f72f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Saved: /content/drive/MyDrive/vae_cifar10_runs/samples_from_loaded.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "#  Plotting module for VAE training\n",
        "#  Generates: recon loss, KL loss, total loss, beta curve,\n",
        "#  and optional latent histograms + recon grids\n",
        "# ============================================================\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torchvision.utils import make_grid, save_image\n",
        "\n",
        "log_path = os.path.join(cfg.out_dir, \"train_log.csv\")\n",
        "plot_dir = os.path.join(cfg.out_dir, \"plots\")\n",
        "os.makedirs(plot_dir, exist_ok=True)\n",
        "\n",
        "def save_plt(path):\n",
        "    plt.savefig(path, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv(log_path)\n",
        "\n",
        "print(\"Loaded training log from:\", log_path)\n",
        "df.head()\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(df[\"epoch\"], df[\"avg_recon\"], label=\"Reconstruction Loss\", linewidth=2)\n",
        "plt.plot(df[\"epoch\"], df[\"avg_kl\"], label=\"KL Loss\", linewidth=2)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"VAE Reconstruction & KL Loss\")\n",
        "plt.grid(True)\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "save_plt(os.path.join(plot_dir, \"VAE_Reconstruction_KL_Loss.png\"))\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(df[\"epoch\"], df[\"avg_total\"], label=\"Total Loss\", color=\"black\", linewidth=2)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Total Loss Over Training\")\n",
        "plt.grid(True)\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "save_plt(os.path.join(plot_dir, \"total_loss.png\"))\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(df[\"epoch\"], df[\"beta\"], label=\"KL Weight β\", color=\"purple\", linewidth=2)\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"β\")\n",
        "plt.title(\"KL Weight Schedule\")\n",
        "plt.grid(True)\n",
        "# plt.legend()\n",
        "# plt.show()\n",
        "save_plt(os.path.join(plot_dir, \"KL_weight_schedule.png\"))\n",
        "\n",
        "# Load a batch and extract latent means\n",
        "vae.eval()\n",
        "all_mu = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, _ in trainloader:\n",
        "        x = x.to(device)\n",
        "        mu, logvar = vae.enc(x)\n",
        "        all_mu.append(mu.cpu())\n",
        "        if len(all_mu) > 30:   # about 30 batches (~2000 images)\n",
        "            break\n",
        "\n",
        "all_mu = torch.cat(all_mu, dim=0)\n",
        "z0 = all_mu[:, 0].numpy()    # pick latent dimension 0\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.histplot(z0, bins=50, kde=True)\n",
        "plt.title(\"Histogram of Latent Dimension z₀\")\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "# plt.show()\n",
        "save_plt(os.path.join(plot_dir, \"latent_dimension_histogram.png\"))\n",
        "\n",
        "vae.eval()\n",
        "\n",
        "x, _ = next(iter(testloader))\n",
        "x = x[:8].to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    xr, _, _, _ = vae(x)\n",
        "\n",
        "# Denormalize\n",
        "x_dn = denorm(x)\n",
        "xr_dn = denorm(xr)\n",
        "\n",
        "# Stack original + recon under each other\n",
        "comparison = torch.cat([x_dn, xr_dn], dim=0)\n",
        "\n",
        "grid = make_grid(comparison, nrow=8)\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.title(\"Original (top) vs Reconstruction (bottom)\")\n",
        "plt.imshow(grid.permute(1,2,0).cpu().numpy())\n",
        "plt.axis('off')\n",
        "# plt.show()\n",
        "save_plt(os.path.join(plot_dir, \"original_vs_reconstruction.png\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIkX-cqlOAig",
        "outputId": "bb13f96d-e5ab-4ecc-a271-66417af9de6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded training log from: /content/drive/MyDrive/vae_cifar10_runs/train_log.csv\n"
          ]
        }
      ]
    }
  ]
}